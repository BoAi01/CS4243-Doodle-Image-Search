{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae588f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, sys\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.utils.data.dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from training_config import doodles, reals, doodle_size, real_size, NUM_CLASSES\n",
    "from utils import *  # bad practice, nvm\n",
    "from losses import compute_contrastive_loss_from_feats\n",
    "\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73c2e71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_dataset(datasets, size):\n",
    "    combined_dataset = {}\n",
    "    for name, dataset in datasets.items():\n",
    "        for class_name, class_data in dataset.items():\n",
    "            if class_name not in combined_dataset:\n",
    "                combined_dataset[class_name] = []\n",
    "            # resize data so they can be stacked\n",
    "            resized = []\n",
    "            for data in class_data:\n",
    "                resized.append(cv2.resize(data, (size, size), interpolation=cv2.INTER_AREA))\n",
    "            resized = np.stack(resized, axis=0)\n",
    "            combined_dataset[class_name].append(resized)\n",
    "    for class_name, lst_datasets in combined_dataset.items():\n",
    "        combined_dataset[class_name] = np.concatenate(lst_datasets, axis=0)\n",
    "    return combined_dataset\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    DATASET_DIR = {True: 'dataset/dataset_train.npy', False: 'dataset/dataset_test.npy'}\n",
    "\n",
    "    def __init__(self, doodles_list, real_list, doodle_size, real_size, train: bool):\n",
    "        super(ImageDataset, self).__init__()\n",
    "\n",
    "        dataset = np.load(self.DATASET_DIR[train], allow_pickle=True)[()]\n",
    "\n",
    "        doodle_datasets = {name: data for name, data in dataset.items() if name in doodles_list}\n",
    "        real_datasets = {name: data for name, data in dataset.items() if name in real_list}\n",
    "        self.doodle_dict = combined_dataset(doodle_datasets, doodle_size)\n",
    "        self.real_dict = combined_dataset(real_datasets, real_size)\n",
    "\n",
    "        # sanity check\n",
    "        assert set(self.doodle_dict.keys()) == set(self.real_dict.keys()), \\\n",
    "            f'doodle and real images label classes do not match'\n",
    "\n",
    "        # process classes\n",
    "        label_idx = {}\n",
    "        for key in self.doodle_dict.keys():\n",
    "            if key not in label_idx:\n",
    "                label_idx[key] = len(label_idx)\n",
    "        self.label_idx = label_idx\n",
    "\n",
    "        # parse data and labels\n",
    "        self.doodle_data, self.doodle_label = self._return_x_y_pairs(self.doodle_dict, label_idx)\n",
    "        self.real_data, self.real_label = self._return_x_y_pairs(self.real_dict, label_idx)\n",
    "\n",
    "        # data preprocessing\n",
    "        self.doodle_preprocess = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(doodle_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((self.doodle_data/255).mean(), (self.doodle_data/255).std())   # IMPORTANT / 255\n",
    "        ])\n",
    "\n",
    "        self.real_preprocess = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(real_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((self.real_data/255).mean(axis=(0, 1, 2)), (self.real_data/255).std(axis=(0, 1, 2)))\n",
    "        ])\n",
    "\n",
    "        print(f'Train = {train}. Doodle list: {doodles_list}, \\n real list: {real_list}. \\n classes: {label_idx.keys()} \\n'\n",
    "              f'Doodle data size {len(self.doodle_data)}, real data size {len(self.real_data)}, '\n",
    "              f'ratio {len(self.doodle_data)/len(self.real_data)}')\n",
    "\n",
    "    def _return_x_y_pairs(self, data_dict, category_mapping):\n",
    "        xs, ys = [], []\n",
    "        for key in data_dict.keys():\n",
    "            data = data_dict[key]\n",
    "            labels = [category_mapping[key]] * len(data)\n",
    "            xs.append(data)\n",
    "            ys.extend(labels)\n",
    "        return np.concatenate(xs, axis=0), np.array(ys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # naive sampling scheme - sample with replacement\n",
    "        # sample label first so that doodle and real data belong to the same category\n",
    "        label = random.choice(list(self.label_idx.keys()))\n",
    "        doodle_data = self.doodle_preprocess(random.choice(self.doodle_dict[label]))\n",
    "        real_data = self.real_preprocess(random.choice(self.real_dict[label]))\n",
    "        numer_label = self.label_idx[label]\n",
    "        return doodle_data, numer_label, real_data, numer_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.doodle_data), len(self.real_data)) # could be arbitrary number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c258fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class V2ConvNet(nn.Module):\n",
    "    def __init__(self, in_c, \n",
    "                 num_classes, \n",
    "                 channel_list=[64, 128, 192, 256, 512], \n",
    "                 pool_option=(1,1), \n",
    "                 hidden=256, \n",
    "                 dropout=0.2, \n",
    "                 add_layers=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        layer1 = nn.Conv2d(in_c, channel_list[0], kernel_size=3)\n",
    "        layer2 = nn.Conv2d(channel_list[0], channel_list[0], kernel_size=3)\n",
    "        layers = [layer1, layer2]\n",
    "        \n",
    "        for i in range(1, len(channel_list)):\n",
    "            layers.append(\n",
    "                nn.Conv2d(channel_list[i-1], channel_list[i], kernel_size=3, stride=2, padding=1, bias=True)\n",
    "            )\n",
    "            layers.append(\n",
    "                nn.Conv2d(channel_list[i], channel_list[i], kernel_size=3, stride=2, padding=1, bias=True)\n",
    "            )\n",
    "            layers.append(\n",
    "                nn.BatchNorm2d(channel_list[i])\n",
    "            )\n",
    "            layers.append(\n",
    "                nn.Dropout(dropout)\n",
    "            )\n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "        self.conv = nn.Sequential(*layers)\n",
    "        \n",
    "        self.flatten = nn.AdaptiveAvgPool2d(pool_option)\n",
    "            \n",
    "        self.fc = nn.Sequential(*[\n",
    "            nn.Linear(pool_option[0] * pool_option[1] * channel_list[-1], hidden),\n",
    "            nn.Linear(hidden, num_classes)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, return_feats=False):\n",
    "        feats = self.conv(x)\n",
    "        x = x.view(x.size(0), 512, -1).mean(2)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        if return_feats:\n",
    "            return x, feats\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0082e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 9])\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "V2ConvNet                                --\n",
      "├─Sequential: 1-1                        --\n",
      "│    └─Conv2d: 2-1                       1,792\n",
      "│    └─Conv2d: 2-2                       36,928\n",
      "│    └─Conv2d: 2-3                       73,856\n",
      "│    └─Conv2d: 2-4                       147,584\n",
      "│    └─BatchNorm2d: 2-5                  256\n",
      "│    └─Dropout: 2-6                      --\n",
      "│    └─ReLU: 2-7                         --\n",
      "│    └─Conv2d: 2-8                       221,376\n",
      "│    └─Conv2d: 2-9                       331,968\n",
      "│    └─BatchNorm2d: 2-10                 384\n",
      "│    └─Dropout: 2-11                     --\n",
      "│    └─ReLU: 2-12                        --\n",
      "│    └─Conv2d: 2-13                      442,624\n",
      "│    └─Conv2d: 2-14                      590,080\n",
      "│    └─BatchNorm2d: 2-15                 512\n",
      "│    └─Dropout: 2-16                     --\n",
      "│    └─ReLU: 2-17                        --\n",
      "│    └─Conv2d: 2-18                      1,180,160\n",
      "│    └─Conv2d: 2-19                      2,359,808\n",
      "│    └─BatchNorm2d: 2-20                 1,024\n",
      "│    └─Dropout: 2-21                     --\n",
      "│    └─ReLU: 2-22                        --\n",
      "├─AdaptiveAvgPool2d: 1-2                 --\n",
      "├─Sequential: 1-3                        --\n",
      "│    └─Linear: 2-23                      131,328\n",
      "│    └─Linear: 2-24                      2,313\n",
      "=================================================================\n",
      "Total params: 5,521,993\n",
      "Trainable params: 5,521,993\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "x = torch.rand(100, 3, 64, 64)\n",
    "net = V2ConvNet(3, 9, [64, 128, 192, 256, 512])\n",
    "y = net(x)\n",
    "print (y.shape)\n",
    "print (summary(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2623cf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed(0)  # zero seed by default\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6794928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(doodle_channels, real_channels, hidden, dropout):\n",
    "    doodle_model = V2ConvNet(1, 9, channel_list=doodle_channels, hidden=hidden)\n",
    "    real_model = V2ConvNet(3, 9, channel_list=real_channels, hidden=hidden)\n",
    "    \n",
    "    return doodle_model, real_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be1c08a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(batch_size):\n",
    "    train_set = ImageDataset(doodles, reals, doodle_size, real_size, train=True)\n",
    "    val_set = ImageDataset(doodles, reals, doodle_size, real_size, train=False)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True, drop_last=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True, drop_last=True)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce6b1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch, model1, model2, train_loader, val_loader, criterion, optimizer, scheduler):\n",
    "    loss1_model1 = AverageMeter()\n",
    "    loss1_model2 = AverageMeter()\n",
    "    loss2_model1 = AverageMeter()\n",
    "    loss2_model2 = AverageMeter()\n",
    "    loss3_combined = AverageMeter()\n",
    "    acc_model1 = AverageMeter()\n",
    "    acc_model2 = AverageMeter()\n",
    "\n",
    "    model1.train()\n",
    "    model2.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    c1, c2, t = 0, 0, 0.1\n",
    "    \n",
    "    metadata = {}\n",
    "\n",
    "    for i, (x1, y1, x2, y2) in enumerate(train_loader):\n",
    "        # doodle, label, real, label\n",
    "        x1, y1, x2, y2 = x1.cuda(), y1.cuda(), x2.cuda(), y2.cuda()\n",
    "\n",
    "        # train model1 (doodle)\n",
    "        pred1, feats1 = model1(x1, return_feats=True)\n",
    "        loss_1 = criterion(pred1, y1)  # classification loss\n",
    "        loss1_model1.update(loss_1.item())\n",
    "        loss_model1 = loss_1\n",
    "\n",
    "        # train model2 (real)\n",
    "        pred2, feats2 = model2(x2, return_feats=True)\n",
    "        loss_1 = criterion(pred2, y2)  # classification loss\n",
    "        loss1_model2.update(loss_1.item())\n",
    "        loss_model2 = loss_1\n",
    "\n",
    "        loss = loss_model1 + loss_model2\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # statistics\n",
    "        acc_model1.update(compute_accuracy(pred1, y1))\n",
    "        acc_model2.update(compute_accuracy(pred2, y2))\n",
    "\n",
    "        # optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    metadata.update({\n",
    "        'train acc 1': float(acc_model1.avg),\n",
    "        'train acc 2': float(acc_model2.avg),\n",
    "        'train epoch': epoch,\n",
    "        'l1m1': float(loss1_model1.avg),\n",
    "        'l1m2': float(loss1_model2.avg),\n",
    "        'total_loss': float(total_loss / base_bs)\n",
    "    })\n",
    "\n",
    "    # validation\n",
    "    model1.eval(), model1.eval()\n",
    "    acc_model1.reset(), acc_model2.reset()\n",
    "    with torch.no_grad():\n",
    "        for i, (x1, y1, x2, y2) in enumerate(val_loader):\n",
    "            pred1, feats1 = model1(x1, return_feats=True)\n",
    "            pred2, feats2 = model2(x2, return_feats=True)\n",
    "            acc_model1.update(compute_accuracy(pred1, y1))\n",
    "            acc_model2.update(compute_accuracy(pred2, y2))\n",
    "\n",
    "    metadata.update({\n",
    "        'val epoch': epoch,\n",
    "        'val acc 1': float(acc_model1.avg),\n",
    "        'val acc 2': float(acc_model2.avg),\n",
    "    })\n",
    "\n",
    "    scheduler.step()\n",
    "  \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c793438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def train_model(config=None):\n",
    "    num_epochs, base_bs, base_lr = 20, 512, 2e-2\n",
    "    \n",
    "    model1, model2 = build_model(\n",
    "                        config[\"channel_combos\"],\n",
    "                        config[\"channel_combos\"],\n",
    "                        config[\"hidden_dim\"],\n",
    "                        config[\"dropout\"]\n",
    "                    )\n",
    "    \n",
    "    model1 = nn.DataParallel(model1).cuda()\n",
    "    model2 = nn.DataParallel(model2).cuda()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        params=list(model1.parameters()) + list(model2.parameters()), \n",
    "        lr=config[\"learning_rate\"], \n",
    "        weight_decay=3e-4\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    epochs = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_data = train_epoch(\n",
    "            epoch,\n",
    "            model1, \n",
    "            model2, \n",
    "            train_loader, \n",
    "            val_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            scheduler\n",
    "        )\n",
    "\n",
    "        epochs.append(epoch_data)\n",
    "        \n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6ebe02e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nparameters_dict = {\\n    \\'channel_combos\\': {\\n        \\'values\\': [\\n                [64, 128, 192, 256, 512],\\n                [64, 128, 256, 512],\\n                [32, 64, 64, 512],\\n                [16, 32, 128, 512],\\n                [32, 64, 192, 512],\\n                [32, 128, 192, 512]\\n            ]\\n        },\\n    \\'hidden_dim\\': {\\n        \"values\": [64, 128, 256, 512]\\n    },\\n    \\'dropout\\': {\\n          \\'values\\': [0.3, 0.4, 0.5]\\n        }\\n    }\\n\\nsweep_config[\\'parameters\\'] = parameters_dict\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "parameters_dict = {\n",
    "    'channel_combos': {\n",
    "        'values': [\n",
    "                [64, 128, 192, 256, 512],\n",
    "                [64, 128, 256, 512],\n",
    "                [32, 64, 64, 512],\n",
    "                [16, 32, 128, 512],\n",
    "                [32, 64, 192, 512],\n",
    "                [32, 128, 192, 512]\n",
    "            ]\n",
    "        },\n",
    "    'hidden_dim': {\n",
    "        \"values\": [64, 128, 256, 512]\n",
    "    },\n",
    "    'dropout': {\n",
    "          'values': [0.3, 0.4, 0.5]\n",
    "        }\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b869d51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train = True. Doodle list: ['sketchy_doodle', 'tuberlin', 'google_doodles'], \n",
      " real list: ['sketchy_real', 'google_real', 'cifar']. \n",
      " classes: dict_keys(['airplane', 'car', 'cat', 'dog', 'frog', 'horse', 'truck', 'bird', 'ship']) \n",
      "Doodle data size 7022, real data size 46364, ratio 0.15145371408851696\n",
      "Train = False. Doodle list: ['sketchy_doodle', 'tuberlin', 'google_doodles'], \n",
      " real list: ['sketchy_real', 'google_real', 'cifar']. \n",
      " classes: dict_keys(['airplane', 'car', 'cat', 'dog', 'frog', 'horse', 'truck', 'bird', 'ship']) \n",
      "Doodle data size 1764, real data size 9341, ratio 0.18884487742211756\n"
     ]
    }
   ],
   "source": [
    "base_bs = 512\n",
    "train_loader, val_loader = build_dataset(base_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd3349e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>\n",
      "    Traceback (most recent call last):\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "AssertionError:     can only test a child processself._shutdown_workers()\n",
      "\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>\n",
      "    Traceback (most recent call last):\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "if w.is_alive():    \n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: \n",
      "can only test a child processException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "\n",
      "can only test a child process: AssertionError    if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f62b0574320>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1341, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/rishabh/miniconda3/envs/Rish4243/lib/python3.7/multiprocessing/process.py\", line 151, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    }
   ],
   "source": [
    "config1 = {\n",
    "    \"channel_combos\": [64, 128, 192, 256, 512],\n",
    "    \"hidden_dim\": 256,\n",
    "    \"dropout\": 0.3,\n",
    "    \"learning_rate\": 0.025\n",
    "}\n",
    "\n",
    "history1 = train_model(config1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c6633",
   "metadata": {},
   "outputs": [],
   "source": [
    "config2 = {\n",
    "    \"channel_combos\": [64, 128, 256, 512],\n",
    "    \"hidden_dim\": 512,\n",
    "    \"dropout\": 0.5,\n",
    "    \"learning_rate\": 2e-2\n",
    "}\n",
    "\n",
    "history2 = train_model(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4843f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config3 = {\n",
    "    \"channel_combos\": [32, 64, 64, 512],\n",
    "    \"hidden_dim\": 128,\n",
    "    \"dropout\": 0.4,\n",
    "    \"learning_rate\": 0.05\n",
    "}\n",
    "\n",
    "history3 = train_model(config3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfbdf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "config4 = {\n",
    "    \"channel_combos\": [16, 32, 128, 512],\n",
    "    \"hidden_dim\": 256,\n",
    "    \"dropout\": 0.3,\n",
    "    \"learning_rate\": 2e-2\n",
    "}\n",
    "\n",
    "history4 = train_model(config4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c183e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "config5 = {\n",
    "    \"channel_combos\": [32, 64, 192, 512],\n",
    "    \"hidden_dim\": 512,\n",
    "    \"dropout\": 0.5,\n",
    "    \"learning_rate\": 4e-2\n",
    "}\n",
    "\n",
    "history5 = train_model(config5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3413c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config6 = {\n",
    "    \"channel_combos\": [32, 128, 192, 512],\n",
    "    \"hidden_dim\": 128,\n",
    "    \"dropout\": 0.5,\n",
    "    \"learning_rate\": 2e-3\n",
    "}\n",
    "\n",
    "history6 = train_model(config6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1d8e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = [\n",
    "    history1,\n",
    "    history2,\n",
    "    history3,\n",
    "    history4,\n",
    "    history5,\n",
    "    history6,\n",
    "]\n",
    "\n",
    "\n",
    "def plot_v2_history(histories):\n",
    "    for i in range"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
