{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fbbb1fa-9413-42ca-9f4d-be00d266e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from random import randint\n",
    "import time\n",
    "import utils\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd781f64-7e78-4186-8ddb-2507bc991e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(dataset):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, (k, v) in enumerate(dataset.items()):\n",
    "        X.append(v)\n",
    "        y.append([i] * v.shape[0])\n",
    "    X = np.concatenate(X)\n",
    "    y = np.concatenate(y)\n",
    "    X = torch.from_numpy(X).type(torch.float32)\n",
    "    y = torch.from_numpy(y).type(torch.int64)\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    return dataset, dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "067b539d-3ee8-4810-af41-4a5d152f8882",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load('dataset/dataset.npy', allow_pickle=True)[()]\n",
    "train_dataset, train_dataloader = process_dataset(dataset['cifar_train'])\n",
    "test_dataset, test_dataloader = process_dataset(dataset['cifar_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b7d3e93-05e6-4b3a-a5ed-9dacfec56ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device.\n",
      "MLP(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=3072, out_features=1024, bias=False)\n",
      "  (fc2): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (fc3): Linear(in_features=512, out_features=256, bias=False)\n",
      "  (fc4): Linear(in_features=256, out_features=128, bias=False)\n",
      "  (fc5): Linear(in_features=128, out_features=64, bias=False)\n",
      "  (fc6): Linear(in_features=64, out_features=32, bias=False)\n",
      "  (fc7): Linear(in_features=32, out_features=10, bias=False)\n",
      ")\n",
      "There are 3844416 (3.84 million) parameters in this neural network\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device.\")\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim, y_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(x_dim, 1024, bias=False)\n",
    "        self.fc2 = nn.Linear(1024, 512, bias=False)\n",
    "        self.fc3 = nn.Linear(512, 256, bias=False)\n",
    "        self.fc4 = nn.Linear(256, 128, bias=False)\n",
    "        self.fc5 = nn.Linear(128, 64, bias=False)\n",
    "        self.fc6 = nn.Linear(64, 32, bias=False)\n",
    "        self.fc7 = nn.Linear(32, y_dim, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = self.fc7(x)\n",
    "        return x\n",
    "\n",
    "model = MLP(3072, 128, 10).to(device)\n",
    "print(model)\n",
    "utils.display_num_param(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a16c4067-79ee-4b84-8d73-572251ac6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23d9f3e5-715b-4e2c-98d3-9967b7142294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"Loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf936fea-3d34-4ced-a484-84cabce852c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46071239-c6b8-4fc3-9f04-cc70419a8ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Loss: 2.381329  [    0/45000]\n",
      "Loss: 2.255355  [ 3200/45000]\n",
      "Loss: 1.810407  [ 6400/45000]\n",
      "Loss: 1.718560  [ 9600/45000]\n",
      "Loss: 1.918092  [12800/45000]\n",
      "Loss: 1.809936  [16000/45000]\n",
      "Loss: 1.628113  [19200/45000]\n",
      "Loss: 1.816442  [22400/45000]\n",
      "Loss: 1.645598  [25600/45000]\n",
      "Loss: 1.624461  [28800/45000]\n",
      "Loss: 1.754855  [32000/45000]\n",
      "Loss: 1.467234  [35200/45000]\n",
      "Loss: 1.833449  [38400/45000]\n",
      "Loss: 1.656598  [41600/45000]\n",
      "Loss: 1.668537  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 33.5%, Avg loss: 1.857549 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Loss: 1.987152  [    0/45000]\n",
      "Loss: 1.934283  [ 3200/45000]\n",
      "Loss: 1.527460  [ 6400/45000]\n",
      "Loss: 1.646308  [ 9600/45000]\n",
      "Loss: 1.825963  [12800/45000]\n",
      "Loss: 1.557711  [16000/45000]\n",
      "Loss: 1.495553  [19200/45000]\n",
      "Loss: 1.969631  [22400/45000]\n",
      "Loss: 1.847742  [25600/45000]\n",
      "Loss: 1.589469  [28800/45000]\n",
      "Loss: 1.543301  [32000/45000]\n",
      "Loss: 1.827369  [35200/45000]\n",
      "Loss: 1.766272  [38400/45000]\n",
      "Loss: 1.576057  [41600/45000]\n",
      "Loss: 1.506021  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 37.0%, Avg loss: 1.793431 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Loss: 1.498402  [    0/45000]\n",
      "Loss: 1.588851  [ 3200/45000]\n",
      "Loss: 1.838488  [ 6400/45000]\n",
      "Loss: 1.752931  [ 9600/45000]\n",
      "Loss: 1.702431  [12800/45000]\n",
      "Loss: 1.548839  [16000/45000]\n",
      "Loss: 1.532035  [19200/45000]\n",
      "Loss: 1.536906  [22400/45000]\n",
      "Loss: 1.558934  [25600/45000]\n",
      "Loss: 1.465557  [28800/45000]\n",
      "Loss: 1.638899  [32000/45000]\n",
      "Loss: 1.372398  [35200/45000]\n",
      "Loss: 1.416961  [38400/45000]\n",
      "Loss: 1.588399  [41600/45000]\n",
      "Loss: 1.514331  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 38.1%, Avg loss: 1.808062 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Loss: 1.505689  [    0/45000]\n",
      "Loss: 1.500849  [ 3200/45000]\n",
      "Loss: 1.606032  [ 6400/45000]\n",
      "Loss: 1.391171  [ 9600/45000]\n",
      "Loss: 1.600930  [12800/45000]\n",
      "Loss: 1.360702  [16000/45000]\n",
      "Loss: 1.513796  [19200/45000]\n",
      "Loss: 1.590687  [22400/45000]\n",
      "Loss: 1.673779  [25600/45000]\n",
      "Loss: 1.638453  [28800/45000]\n",
      "Loss: 1.478745  [32000/45000]\n",
      "Loss: 1.581163  [35200/45000]\n",
      "Loss: 1.447611  [38400/45000]\n",
      "Loss: 1.994112  [41600/45000]\n",
      "Loss: 1.589832  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 40.0%, Avg loss: 1.753277 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Loss: 1.931573  [    0/45000]\n",
      "Loss: 1.455390  [ 3200/45000]\n",
      "Loss: 1.611863  [ 6400/45000]\n",
      "Loss: 1.485624  [ 9600/45000]\n",
      "Loss: 1.266916  [12800/45000]\n",
      "Loss: 1.334640  [16000/45000]\n",
      "Loss: 1.319103  [19200/45000]\n",
      "Loss: 1.678518  [22400/45000]\n",
      "Loss: 1.368324  [25600/45000]\n",
      "Loss: 1.659529  [28800/45000]\n",
      "Loss: 1.426079  [32000/45000]\n",
      "Loss: 1.258964  [35200/45000]\n",
      "Loss: 1.479707  [38400/45000]\n",
      "Loss: 1.559505  [41600/45000]\n",
      "Loss: 1.551661  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 40.0%, Avg loss: 1.776010 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Loss: 1.600749  [    0/45000]\n",
      "Loss: 1.487382  [ 3200/45000]\n",
      "Loss: 1.430047  [ 6400/45000]\n",
      "Loss: 1.209001  [ 9600/45000]\n",
      "Loss: 1.350237  [12800/45000]\n",
      "Loss: 1.502099  [16000/45000]\n",
      "Loss: 1.568553  [19200/45000]\n",
      "Loss: 1.797066  [22400/45000]\n",
      "Loss: 1.993672  [25600/45000]\n",
      "Loss: 1.452898  [28800/45000]\n",
      "Loss: 1.437221  [32000/45000]\n",
      "Loss: 1.524346  [35200/45000]\n",
      "Loss: 1.407842  [38400/45000]\n",
      "Loss: 1.630419  [41600/45000]\n",
      "Loss: 1.354741  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 40.5%, Avg loss: 1.801687 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Loss: 1.206397  [    0/45000]\n",
      "Loss: 1.368888  [ 3200/45000]\n",
      "Loss: 1.305667  [ 6400/45000]\n",
      "Loss: 1.438437  [ 9600/45000]\n",
      "Loss: 1.304977  [12800/45000]\n",
      "Loss: 1.601433  [16000/45000]\n",
      "Loss: 1.787431  [19200/45000]\n",
      "Loss: 1.480967  [22400/45000]\n",
      "Loss: 1.323349  [25600/45000]\n",
      "Loss: 1.550272  [28800/45000]\n",
      "Loss: 1.678915  [32000/45000]\n",
      "Loss: 1.746389  [35200/45000]\n",
      "Loss: 1.606042  [38400/45000]\n",
      "Loss: 1.446316  [41600/45000]\n",
      "Loss: 1.472335  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 40.1%, Avg loss: 1.754080 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Loss: 1.439453  [    0/45000]\n",
      "Loss: 1.384084  [ 3200/45000]\n",
      "Loss: 1.378090  [ 6400/45000]\n",
      "Loss: 1.439729  [ 9600/45000]\n",
      "Loss: 1.588616  [12800/45000]\n",
      "Loss: 1.380994  [16000/45000]\n",
      "Loss: 1.484120  [19200/45000]\n",
      "Loss: 1.458396  [22400/45000]\n",
      "Loss: 1.580606  [25600/45000]\n",
      "Loss: 1.431137  [28800/45000]\n",
      "Loss: 1.602082  [32000/45000]\n",
      "Loss: 1.505241  [35200/45000]\n",
      "Loss: 1.278504  [38400/45000]\n",
      "Loss: 1.363856  [41600/45000]\n",
      "Loss: 1.202891  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 42.5%, Avg loss: 1.760292 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Loss: 1.660601  [    0/45000]\n",
      "Loss: 1.200668  [ 3200/45000]\n",
      "Loss: 1.372638  [ 6400/45000]\n",
      "Loss: 1.315257  [ 9600/45000]\n",
      "Loss: 1.383102  [12800/45000]\n",
      "Loss: 1.585621  [16000/45000]\n",
      "Loss: 1.432064  [19200/45000]\n",
      "Loss: 1.396197  [22400/45000]\n",
      "Loss: 1.627026  [25600/45000]\n",
      "Loss: 1.060726  [28800/45000]\n",
      "Loss: 1.377492  [32000/45000]\n",
      "Loss: 1.505269  [35200/45000]\n",
      "Loss: 1.544310  [38400/45000]\n",
      "Loss: 1.329556  [41600/45000]\n",
      "Loss: 1.414777  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 42.6%, Avg loss: 1.782689 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Loss: 0.992043  [    0/45000]\n",
      "Loss: 1.404229  [ 3200/45000]\n",
      "Loss: 1.446456  [ 6400/45000]\n",
      "Loss: 1.550253  [ 9600/45000]\n",
      "Loss: 1.150048  [12800/45000]\n",
      "Loss: 1.493218  [16000/45000]\n",
      "Loss: 1.598538  [19200/45000]\n",
      "Loss: 1.668038  [22400/45000]\n",
      "Loss: 1.494890  [25600/45000]\n",
      "Loss: 1.348891  [28800/45000]\n",
      "Loss: 1.498211  [32000/45000]\n",
      "Loss: 1.274801  [35200/45000]\n",
      "Loss: 1.493257  [38400/45000]\n",
      "Loss: 1.266895  [41600/45000]\n",
      "Loss: 1.414438  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 40.8%, Avg loss: 1.788061 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Loss: 1.616247  [    0/45000]\n",
      "Loss: 1.562313  [ 3200/45000]\n",
      "Loss: 1.365550  [ 6400/45000]\n",
      "Loss: 1.753764  [ 9600/45000]\n",
      "Loss: 1.477705  [12800/45000]\n",
      "Loss: 1.246102  [16000/45000]\n",
      "Loss: 1.391974  [19200/45000]\n",
      "Loss: 1.778842  [22400/45000]\n",
      "Loss: 1.417659  [25600/45000]\n",
      "Loss: 1.730923  [28800/45000]\n",
      "Loss: 1.740035  [32000/45000]\n",
      "Loss: 1.248467  [35200/45000]\n",
      "Loss: 1.175098  [38400/45000]\n",
      "Loss: 1.288754  [41600/45000]\n",
      "Loss: 1.670636  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 43.3%, Avg loss: 1.746866 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Loss: 1.129248  [    0/45000]\n",
      "Loss: 1.466941  [ 3200/45000]\n",
      "Loss: 1.411249  [ 6400/45000]\n",
      "Loss: 1.420788  [ 9600/45000]\n",
      "Loss: 1.209629  [12800/45000]\n",
      "Loss: 1.593454  [16000/45000]\n",
      "Loss: 1.547511  [19200/45000]\n",
      "Loss: 1.515725  [22400/45000]\n",
      "Loss: 1.511678  [25600/45000]\n",
      "Loss: 1.497393  [28800/45000]\n",
      "Loss: 1.194843  [32000/45000]\n",
      "Loss: 1.424147  [35200/45000]\n",
      "Loss: 1.417140  [38400/45000]\n",
      "Loss: 1.390739  [41600/45000]\n",
      "Loss: 1.415832  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 41.9%, Avg loss: 1.752881 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Loss: 1.022807  [    0/45000]\n",
      "Loss: 1.285729  [ 3200/45000]\n",
      "Loss: 1.467263  [ 6400/45000]\n",
      "Loss: 1.070330  [ 9600/45000]\n",
      "Loss: 1.209375  [12800/45000]\n",
      "Loss: 1.161759  [16000/45000]\n",
      "Loss: 1.214159  [19200/45000]\n",
      "Loss: 1.446540  [22400/45000]\n",
      "Loss: 1.649470  [25600/45000]\n",
      "Loss: 1.498765  [28800/45000]\n",
      "Loss: 1.399306  [32000/45000]\n",
      "Loss: 1.461826  [35200/45000]\n",
      "Loss: 1.688092  [38400/45000]\n",
      "Loss: 1.386488  [41600/45000]\n",
      "Loss: 0.926079  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 42.0%, Avg loss: 1.804307 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Loss: 1.437958  [    0/45000]\n",
      "Loss: 1.600879  [ 3200/45000]\n",
      "Loss: 1.550426  [ 6400/45000]\n",
      "Loss: 1.470191  [ 9600/45000]\n",
      "Loss: 1.316413  [12800/45000]\n",
      "Loss: 1.341792  [16000/45000]\n",
      "Loss: 1.269295  [19200/45000]\n",
      "Loss: 1.826856  [22400/45000]\n",
      "Loss: 1.681772  [25600/45000]\n",
      "Loss: 1.568935  [28800/45000]\n",
      "Loss: 1.145131  [32000/45000]\n",
      "Loss: 1.693706  [35200/45000]\n",
      "Loss: 1.527589  [38400/45000]\n",
      "Loss: 1.415051  [41600/45000]\n",
      "Loss: 1.313865  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 42.5%, Avg loss: 1.743719 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Loss: 1.432423  [    0/45000]\n",
      "Loss: 1.445728  [ 3200/45000]\n",
      "Loss: 1.571093  [ 6400/45000]\n",
      "Loss: 1.447718  [ 9600/45000]\n",
      "Loss: 1.251550  [12800/45000]\n",
      "Loss: 1.290933  [16000/45000]\n",
      "Loss: 1.497012  [19200/45000]\n",
      "Loss: 1.370132  [22400/45000]\n",
      "Loss: 1.507241  [25600/45000]\n",
      "Loss: 1.131135  [28800/45000]\n",
      "Loss: 1.424737  [32000/45000]\n",
      "Loss: 1.319381  [35200/45000]\n",
      "Loss: 1.495929  [38400/45000]\n",
      "Loss: 1.602105  [41600/45000]\n",
      "Loss: 1.603790  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 39.3%, Avg loss: 1.790091 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Loss: 1.360474  [    0/45000]\n",
      "Loss: 1.430439  [ 3200/45000]\n",
      "Loss: 1.469396  [ 6400/45000]\n",
      "Loss: 1.366625  [ 9600/45000]\n",
      "Loss: 1.166831  [12800/45000]\n",
      "Loss: 1.163170  [16000/45000]\n",
      "Loss: 1.224152  [19200/45000]\n",
      "Loss: 1.156202  [22400/45000]\n",
      "Loss: 1.196927  [25600/45000]\n",
      "Loss: 1.594700  [28800/45000]\n",
      "Loss: 1.466179  [32000/45000]\n",
      "Loss: 1.123212  [35200/45000]\n",
      "Loss: 1.262580  [38400/45000]\n",
      "Loss: 1.519757  [41600/45000]\n",
      "Loss: 1.349935  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 41.6%, Avg loss: 1.865407 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Loss: 1.521065  [    0/45000]\n",
      "Loss: 1.227255  [ 3200/45000]\n",
      "Loss: 1.430786  [ 6400/45000]\n",
      "Loss: 1.063501  [ 9600/45000]\n",
      "Loss: 1.475749  [12800/45000]\n",
      "Loss: 1.353469  [16000/45000]\n",
      "Loss: 1.464795  [19200/45000]\n",
      "Loss: 1.254183  [22400/45000]\n",
      "Loss: 1.446276  [25600/45000]\n",
      "Loss: 1.410383  [28800/45000]\n",
      "Loss: 1.678448  [32000/45000]\n",
      "Loss: 1.505673  [35200/45000]\n",
      "Loss: 1.535213  [38400/45000]\n",
      "Loss: 1.147886  [41600/45000]\n",
      "Loss: 1.108069  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 44.5%, Avg loss: 1.793165 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Loss: 0.992022  [    0/45000]\n",
      "Loss: 1.563634  [ 3200/45000]\n",
      "Loss: 1.425695  [ 6400/45000]\n",
      "Loss: 1.418709  [ 9600/45000]\n",
      "Loss: 1.228167  [12800/45000]\n",
      "Loss: 1.298964  [16000/45000]\n",
      "Loss: 1.676116  [19200/45000]\n",
      "Loss: 0.907174  [22400/45000]\n",
      "Loss: 1.295744  [25600/45000]\n",
      "Loss: 1.246495  [28800/45000]\n",
      "Loss: 1.564501  [32000/45000]\n",
      "Loss: 1.460087  [35200/45000]\n",
      "Loss: 1.604266  [38400/45000]\n",
      "Loss: 1.114128  [41600/45000]\n",
      "Loss: 1.372721  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 43.6%, Avg loss: 1.868599 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Loss: 1.340759  [    0/45000]\n",
      "Loss: 1.228941  [ 3200/45000]\n",
      "Loss: 1.271840  [ 6400/45000]\n",
      "Loss: 1.480947  [ 9600/45000]\n",
      "Loss: 1.282855  [12800/45000]\n",
      "Loss: 1.197484  [16000/45000]\n",
      "Loss: 1.289425  [19200/45000]\n",
      "Loss: 1.294680  [22400/45000]\n",
      "Loss: 1.461667  [25600/45000]\n",
      "Loss: 1.161241  [28800/45000]\n",
      "Loss: 1.271830  [32000/45000]\n",
      "Loss: 1.188856  [35200/45000]\n",
      "Loss: 1.566999  [38400/45000]\n",
      "Loss: 1.198799  [41600/45000]\n",
      "Loss: 1.281959  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 43.1%, Avg loss: 1.797623 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Loss: 1.211779  [    0/45000]\n",
      "Loss: 1.363142  [ 3200/45000]\n",
      "Loss: 1.232541  [ 6400/45000]\n",
      "Loss: 1.577758  [ 9600/45000]\n",
      "Loss: 1.100969  [12800/45000]\n",
      "Loss: 1.177279  [16000/45000]\n",
      "Loss: 1.350769  [19200/45000]\n",
      "Loss: 1.582588  [22400/45000]\n",
      "Loss: 1.658181  [25600/45000]\n",
      "Loss: 1.510141  [28800/45000]\n",
      "Loss: 1.289015  [32000/45000]\n",
      "Loss: 1.126602  [35200/45000]\n",
      "Loss: 1.175514  [38400/45000]\n",
      "Loss: 1.372437  [41600/45000]\n",
      "Loss: 1.310728  [44800/45000]\n",
      "Test Error: \n",
      " Accuracy: 44.3%, Avg loss: 1.761400 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9d15f52-14aa-44dc-b225-2f1dd4d4dfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to models/mlp.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"models/mlp.pth\")\n",
    "print(\"Saved PyTorch Model State to models/mlp.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afef0b22-d2bd-48f1-805a-5667b0558448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(3072, 128, 10)\n",
    "model.load_state_dict(torch.load(\"models/mlp.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be06ed6-9e6f-4cfe-890e-af3fcfa04fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cs4243)",
   "language": "python",
   "name": "cs4243"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
